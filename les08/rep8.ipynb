{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4r05wa0tBN17kociM28Vw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pa2e37/dap-2024/blob/main/les08/rep8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "\n",
        "def load_data() -> pd.DataFrame:\n",
        "    iris = load_iris()\n",
        "    return pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "\n",
        "\n",
        "def scale_data(X: pd.DataFrame) -> np.ndarray:\n",
        "    return StandardScaler().fit_transform(X)\n",
        "\n",
        "\n",
        "def apply_dbscan(X_scaled: np.ndarray, eps: float = 0.5, min_samples: int = 5) -> np.ndarray:\n",
        "    model = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "    return model.fit_predict(X_scaled)\n",
        "\n",
        "\n",
        "def plot_clusters(X_scaled: np.ndarray, labels: np.ndarray) -> None:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(\n",
        "        X_scaled[:, 0],\n",
        "        X_scaled[:, 1],\n",
        "        c=labels,\n",
        "        cmap='rainbow',\n",
        "        s=50\n",
        "    )\n",
        "\n",
        "    plt.xlabel('Sepal Length (scaled)')\n",
        "    plt.ylabel('Sepal Width (scaled)')\n",
        "    plt.title('DBSCAN Clustering of Iris Dataset')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 1. Загрузка данных\n",
        "    X = load_data()\n",
        "\n",
        "    # 2. Нормализация\n",
        "    X_scaled = scale_data(X)\n",
        "\n",
        "    # 3. Кластеризация\n",
        "    clusters = apply_dbscan(X_scaled, eps=0.5, min_samples=5)\n",
        "\n",
        "    # 4. Визуализация\n",
        "    plot_clusters(X_scaled, clusters)\n",
        "\n",
        "    # 5. Результаты\n",
        "    print(\"Уникальные кластеры, найденные DBSCAN:\", np.unique(clusters))\n",
        "    print(\"Кластер '-1' — это шум (точки, не отнесённые к кластерам).\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "mDbx2kAW0N0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ответы на вопросы\n",
        "\n",
        "\n",
        "1. В чем заключается задача кластеризации?\n",
        "\n",
        "Кластеризация — это процесс разделения объектов на группы (кластеры), где:\n",
        "\n",
        "элементы внутри одного кластера максимально похожи,\n",
        "\n",
        "элементы из разных кластеров имеют значительные отличия.\n",
        "\n",
        "Формально:\n",
        "Есть множество объектов X = {x1, x2, …, xn} и метрика расстояния d(xi, xj).\n",
        "Необходимо найти разбиение на K подмножеств C1, C2, …, Ck, оптимизирующее некоторый критерий компактности или разделимости.\n",
        "\n",
        "Главное свойство: обучение проходит без меток, то есть без учителя.\n",
        "\n",
        "2. Для чего применяется кластеризация?\n",
        "\n",
        "Кластеризация используется в разных задачах анализа данных:\n",
        "\n",
        "Сегментация:\n",
        "\n",
        "деление клиентов на группы,\n",
        "\n",
        "классификация пользователей по поведению,\n",
        "\n",
        "выделение рыночных аудиторий.\n",
        "\n",
        "Поиск аномалий:\n",
        "\n",
        "обнаружение мошенничества,\n",
        "\n",
        "выявление отклонений в работе оборудования.\n",
        "\n",
        "Сжатие информации:\n",
        "\n",
        "векторное квантование,\n",
        "\n",
        "уменьшение размерности.\n",
        "\n",
        "Предобработка:\n",
        "\n",
        "создание новых признаков,\n",
        "\n",
        "группировка объектов для более качественного обучения.\n",
        "\n",
        "Наука и исследования:\n",
        "\n",
        "биологическая классификация,\n",
        "\n",
        "тематическое разделение документов,\n",
        "\n",
        "анализ ДНК и геномных данных.\n",
        "\n",
        "3. Алгоритм K-средних (метод Ллойда)\n",
        "\n",
        "K-means — итеративная процедура, которая минимизирует разброс точек внутри кластеров.\n",
        "\n",
        "Основные этапы:\n",
        "\n",
        "Инициализация — случайный выбор K центров кластеров.\n",
        "\n",
        "Назначение точек кластерам:\n",
        "Каждая точка относится к ближайшему центру:\n",
        "\n",
        "ci = argminj ||xi - uj||^2\n",
        "\n",
        "\n",
        "Пересчёт центроидов:\n",
        "Центр — это среднее всех точек кластера:\n",
        "\n",
        "uj = (1/|Cj|) * E xi   (для всех xi в Cj)\n",
        "\n",
        "\n",
        "Повторение шагов 2-3 до стабилизации.\n",
        "\n",
        "Функция потерь (сумма квадратов внутрикластерных отклонений):\n",
        "\n",
        "J = Ej E (xi e Cj) ||xi – uj||^2\n",
        "\n",
        "4. Как определить подходящее число кластеров K?\n",
        "\n",
        "Основные методы выбора оптимального K:\n",
        "\n",
        "Метод «локтя» (Elbow):\n",
        "\n",
        "строится график зависимости J(K) от K,\n",
        "\n",
        "выбирается точка, где скорость уменьшения J заметно падает.\n",
        "\n",
        "Силуэтный коэффициент:\n",
        "\n",
        "оценивает качество кластеризации,\n",
        "\n",
        "выбирают K с максимальным средним силуэтом.\n",
        "\n",
        "Формула:\n",
        "\n",
        "s(i) = (b(i) - a(i)) / max(a(i), b(i))\n",
        "\n",
        "\n",
        "где:\n",
        "\n",
        "a(i) — средняя дистанция до точек своего кластера,\n",
        "\n",
        "b(i) — минимальная средняя дистанция до точек других кластеров.\n",
        "\n",
        "Gap Statistic:\n",
        "\n",
        "сравнивает значение J(K) с эталоном (случайно распределённые данные),\n",
        "\n",
        "оптимальный K максимизирует gap.\n",
        "\n",
        "Проверка устойчивости:\n",
        "\n",
        "анализ результатов при разных начальных центрах.\n",
        "\n",
        "5. Алгоритм DBSCAN\n",
        "\n",
        "DBSCAN — плотностной алгоритм кластеризации, умеющий находить кластеры произвольной формы.\n",
        "\n",
        "Основные понятия:\n",
        "\n",
        "ε-окрестность Ne(x): точки в радиусе e.\n",
        "\n",
        "Ядровая точка: |Ne(x)| >= minPts.\n",
        "\n",
        "Прямая достижимость: y достижим из ядровой точки x.\n",
        "\n",
        "Достижимость: цепочка прямой достижимости между точками.\n",
        "\n",
        "Параметры:\n",
        "\n",
        "e — радиус поиска соседей,\n",
        "\n",
        "minPts — минимальное число точек для ядровой точки.\n",
        "\n",
        "Алгоритм:\n",
        "\n",
        "Определение ядровых точек по e и minPts.\n",
        "\n",
        "Формирование кластеров вокруг ядровых точек за счёт достижимых элементов.\n",
        "\n",
        "Точки, не попавшие ни в один кластер, маркируются как шум (-1).\n",
        "\n",
        "Плюсы:\n",
        "\n",
        "Не нужно задавать количество кластеров.\n",
        "\n",
        "Работает с кластерами произвольной формы.\n",
        "\n",
        "Устойчив к выбросам.\n",
        "\n",
        "Не зависит от порядка обработки точек.\n",
        "\n",
        "Минусы:\n",
        "\n",
        "Сильно зависит от выбора ε и minPts.\n",
        "\n",
        "Сложно применять при разной плотности кластеров.\n",
        "\n",
        "Результат зависит от метрики расстояния.\n",
        "\n",
        "Пример использования:\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
        "labels = dbscan.fit_predict(X)"
      ],
      "metadata": {
        "id": "szSU-7Zn0TMD"
      }
    }
  ]
}